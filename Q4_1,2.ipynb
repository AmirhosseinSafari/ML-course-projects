{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q4\n",
        "\n",
        "part 1\n",
        "\n"
      ],
      "metadata": {
        "id": "mYlNYYuTagz5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJUXClRNIjAa",
        "outputId": "ff710616-0815-4dd5-b300-1d3172ea9e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes with Laplace Smoothing Accuracy: 0.5551428571428572\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Train Naive Bayes with Laplace smoothing\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model on test set\n",
        "y_pred = nb.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Naive Bayes with Laplace Smoothing Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4\n",
        "\n",
        "part 2"
      ],
      "metadata": {
        "id": "_DvOqcLSa14y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "\n",
        "# Train SVM models\n",
        "c_values = [0.01, 0.1, 1, 10]\n",
        "kernels = ['linear', 'rbf', 'poly']\n",
        "\n",
        "for kernel in kernels:\n",
        "    for c in c_values:\n",
        "        # One vs. one\n",
        "        svm_ovo = OneVsOneClassifier(SVC(C=c, kernel=kernel))\n",
        "        svm_ovo.fit(X_train, y_train)\n",
        "        accuracy_ovo = svm_ovo.score(X_test, y_test)\n",
        "        n_sv_ovo = np.sum([len(svm_ovo.estimators_[i].support_) for i in range(len(svm_ovo.estimators_))])\n",
        "        print('C = {}, kernel = {}, One vs. one: Accuracy = {:.2f}%, Number of support vectors = {}'.format(c, kernel, accuracy_ovo*100, n_sv_ovo))\n",
        "\n",
        "        # One vs. all\n",
        "        svm_ova = OneVsRestClassifier(SVC(C=c, kernel=kernel))\n",
        "        svm_ova.fit(X_train, y_train)\n",
        "        accuracy_ova = svm_ova.score(X_test, y_test)\n",
        "        n_sv_ova = np.sum([len(svm_ova.estimators_[i].support_) for i in range(len(svm_ova.estimators_))])\n",
        "        print('C = {}, kernel = {}, One vs. all: Accuracy = {:.2f}%, Number of support vectors = {}'.format(c, kernel, accuracy_ova*100, n_sv_ova))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "D8rBcK3FNadu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C = 0.01, kernel = linear, One vs. one: Accuracy = 87.71%, Number of support vectors = 16211 <br>\n",
        "C = 0.01, kernel = linear, One vs. all: Accuracy = 87.71%, Number of support vectors = 16483 <br>\n",
        "C = 0.1, kernel = linear, One vs. one: Accuracy = 90.38%, Number of support vectors = 27534 <br>\n",
        "C = 0.1, kernel = linear, One vs. all: Accuracy = 90.26%, Number of support vectors = 28152 <br>\n",
        "C = 1, kernel = linear, One vs. one: Accuracy = 91.53%, Number of support vectors = 81770 <br>\n",
        "C = 1, kernel = linear, One vs. all: Accuracy = 91.42%, Number of support vectors = 82332 <br>\n",
        "C = 10, kernel = linear, One vs. one: Accuracy = 91.22%, Number of support vectors = 184826 <br>\n",
        "C = 10, kernel = linear, One vs. all: Accuracy = 91.13%, Number of support vectors = 184923 <br>\n",
        "<br>\n",
        "C = 0.01, kernel = rbf, One vs. one: Accuracy = 93.07%, Number of support vectors = 28251 <br>\n",
        "C = 0.01, kernel = rbf, One vs. all: Accuracy = 93.05%, Number of support vectors = 27881 <br>\n",
        "C = 0.1, kernel = rbf, One vs. one: Accuracy = 95.25%, Number of support vectors = 29302 <br>\n",
        "C = 0.1, kernel = rbf, One vs. all: Accuracy = 95.27%, Number of support vectors = 28412 <br>\n",
        "C = 1, kernel = rbf, One vs. one: Accuracy = 96.37%, Number of support vectors = 29493 <br>\n",
        "C = 1, kernel = rbf, One vs. all: Accuracy = 96.36%, Number of support vectors = 28813 <br>\n",
        "C = 10, kernel = rbf, One vs. one: Accuracy = 95.79%, Number of support vectors = 27036 <br>\n",
        "C = 10, kernel = rbf, One vs. all: Accuracy = 95.79%, Number of support vectors = 26153 <br>\n",
        "<br>\n",
        "C = 0.01, kernel = poly, One vs. one: Accuracy = 93.02%, Number of support vectors = 42372 <br>\n",
        "C = 0.01, kernel = poly, One vs. all: Accuracy = 93.03%, Number of support vectors = 43026 <br>\n",
        "C = 0.1, kernel = poly, One vs. one: Accuracy = 94.77%, Number of support vectors = 78346 <br>\n",
        "C = 0.1, kernel = poly, One vs. all: Accuracy = 94.81%, Number of support vectors = 79625 <br>\n",
        "C = 1, kernel = poly, One vs. one: Accuracy = 94.62%, Number of support vectors = 122743 <br>\n",
        "C = 1, kernel = poly, One vs. all: Accuracy = 94.70%, Number of support vectors = 124765 <br>\n",
        "C = 10, kernel = poly, One vs. one: Accuracy = 93.64%, Number of support vectors = 192324 <br>\n",
        "C = 10, kernel = poly, One vs. all: Accuracy = 93.70%, Number of support vectors = 193247 <br>\n"
      ],
      "metadata": {
        "id": "pOX9X6jXq-at"
      }
    }
  ]
}